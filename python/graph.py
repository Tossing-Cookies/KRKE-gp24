"""KRKE2024_Session4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8RzkrbuPyzWeaSG_bSzWsLonIVZyPol

First of all thank you for participating to the KRKE tutoring activity, in order to get better and fill my gaps I ask you to complete this 5 question survey, it will take you only 2 mins and it will be really useful to me:


[Survey!](https://docs.google.com/forms/d/e/1FAIpQLSd0qlKl3RlwCm6phjxbjW7cLoZXA_4EhZU_Jlwf-yf84DH7Yw/viewform?usp=sf_link)

::Thank you! Let's move to some more interesting topic: Knowledge Representation and Extraction with Python.

We will work on the topic of Natural subcultures and we'll use a toy dataset extracted from [this](https://www.kaggle.com/datasets/brsdincer/all-natural-subcultures-19002021-eosdis/) original dataset, from Kaggle.

Firstly, let's install the [RDFLib](https://rdflib.readthedocs.io/en/stable/) python package.
"""

"""Then upload the csv file we're extracting knowledge from:"""


import pandas as pd

# Path to the CSV file
file_path = 'dataset.csv'

# Load the CSV file into a DataFrame
data = pd.read_csv(file_path)

"""Now we import the necessary Python packages:"""

import rdflib
from rdflib import URIRef, Literal, Namespace, RDF, RDFS, OWL, Graph, XSD

"""Define some useful namespaces and create the graph object which will contain the generated triples."""

# Define your desired namespaces
YOUTH = Namespace("http://w3c.org/youth#")
RDFS = Namespace("http://www.w3.org/2000/01/rdf-schema#")

# Create a new RDFLib graph
g = Graph()

# Bind our namespaces (similarly to the SPARQL "BIND" clause)
g.bind("youth", YOUTH)
g.bind("rdfs", RDFS)

# Define object properties
hasMember = YOUTH.hasMember
affectsPerspective = YOUTH.affectsPerspective
#someProperty = YOUTH.someProperty


# specify the type of the properties!
g.add((hasMember, RDF.type, OWL.ObjectProperty))
g.add((affectsPerspective, RDF.type, OWL.ObjectProperty))

# example object property
#g.add((someProperty, RDF.type, OWL.ObjectProperty))

# Load the data from the CSV file as pandas DataFrame
df = pd.read_csv('dataset.csv')

"""OPTIONAL: Let's load your existing graph:"""

#Â Load your existing graph serialized in Turtle syntax
existing_graph = Graph()
existing_graph.parse("YOUTH.ttl", format="ttl")

"""OPTIONAL: ...and merge it with the newly one created!"""

# the graph merging operation is a mere sum of triples of one graph to another
g = g + existing_graph

"""Here you see how to define a new class:"""

# # Define a new class as a subclass of :? (change the name according to your need)
# new_class_uri = YOUTH["YouthSubculture"]

# # "g.add" adds the triple that follows to the graph
# g.add((new_class_uri, RDF.type, OWL.Class))
# g.add((new_class_uri, RDFS.subClassOf, YOUTH.YouthSubculture))

# """Let's say that you want to adopt the subclasses as"""

# # Generate classes for each *unique* ?_Subgroup as subclasses of :YouthSubculture
# subgroup_classes = {}
# for subgroup in df['?_Subgroup'].unique():
#     # Create a new class for the subgroup
#     class_uri = YOUTH[subgroup.replace(' ', '_')]  # Replace spaces with underscores to obtain proper URIs
#     subgroup_classes[subgroup] = class_uri
#     g.add((class_uri, RDF.type, OWL.Class))
#     g.add((class_uri, RDFS.subClassOf, new_class_uri))

# """[link text](https://)Add triples about other columns:"""

# Iterate over the DataFrame rows

for index, row in df.iterrows():
    # Only proceed if Dis_No is not empty, it is not our case, but it could happen
    if pd.notna(row['Dis_No']):
        subculture_uri = YOUTH["Subculture_" + str(row['YouthSubculture'])]

        # Iterate over each column, adding triples only if the cell is not empty, otherwise you are polluting the graph
        for column in ['Member', 'Perspective']:  # Add all the considered columns here
            if pd.notna(row[column]):
                #property_uri = YOUTH[column] # this is commented since maybe, to explore all the data you want
                                            # to automatically generate properties just with the column header

                # Depending on the column, you might want to specify a different datatype
                if column == 'Year':
                    g.add((subculture_uri, YOUTH.hasMember, Literal(row[column])))
                if column == 'Event_Name':
                    g.add((subculture_uri, YOUTH.affectsPerspective, Literal(row[column])))
                if column == 'HistoricalPeriod':
                    g.add((subculture_uri, YOUTH.hasContext, Literal(row[column], datatype=RDFS.Literal)))

"""Print and serilalize the graph to check our result:"""

print(g.serialize(format='turtle').encode('utf-8'))
# serialize the graph in a new file
with open('YOUTH_data_graph.ttl', 'wb') as f:
    g.serialize(f, format="turtle")

"""
Remember to run the reasoner in order to verify your assertions.
You could use some additional material such as [OOPS - Ontology Pitfall Scanner](https://oops.linkeddata.es/) to improve your modeling quality.
"""